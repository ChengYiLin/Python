{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow build Neuro Net Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/XTIg6qt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='dark'>Import</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='dark'>Simple exercise : using array</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先我們來實作一個 y1 = relu(X * w + b1) 的過程<br>\n",
    "relu 的算法是只要小於 0 ，就歸 0; 大於 0, 則等於它原本的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X*W+b :  [[-0.36000004  0.28      ]]\n",
      "y :  [[0.   0.28]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([[0.4,0.2,0.4]])\n",
    "w = tf.Variable([[-0.5,-0.2],[-0.3,0.4],[-0.5,0.2]])\n",
    "b = tf.Variable([[0.1,0.2]])\n",
    "\n",
    "xwb = tf.matmul(x,w)+b\n",
    "y = tf.nn.relu(xwb)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print('X*W+b : ',sess.run(xwb))\n",
    "    print('y : ',sess.run(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下來我們來實作一個 y1 = sigmoid(X * w + b1) 的過程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X*W+b :  [[-0.36000004  0.28      ]]\n",
      "y :  [[0.41095954 0.5695462 ]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([[0.4,0.2,0.4]])\n",
    "w = tf.Variable([[-0.5,-0.2],[-0.3,0.4],[-0.5,0.2]])\n",
    "b = tf.Variable([[0.1,0.2]])\n",
    "\n",
    "xwb = tf.matmul(x,w)+b\n",
    "y = tf.nn.sigmoid(xwb)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print('X*W+b : ',sess.run(xwb))\n",
    "    print('y : ',sess.run(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在之前我們已經學過 Deep learning 的模型是以 Back propagation 的方式來訓練。<br>\n",
    "因此一開始我們必須先給模型一個亂數初始化的 **權重(weight)** 和 **偏差(bias)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x :  [[0.4 0.2 0.4]]\n",
      "b :  [[-1.2172332  0.9481905]]\n",
      "w : \n",
      " [[-0.36710495 -0.61733115]\n",
      " [ 1.7086805   0.447966  ]\n",
      " [-1.8447334  -1.9523746 ]]\n",
      "\n",
      "y :  [[0.        0.0099014]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([[0.4,0.2,0.4]])\n",
    "w = tf.Variable(tf.random_normal([3,2]))\n",
    "b = tf.Variable(tf.random_normal([1,2]))\n",
    "y = tf.nn.relu(tf.matmul(x,w)+b)\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print('x : ',sess.run(x))\n",
    "    print('b : ',sess.run(b))\n",
    "    print('w : \\n',sess.run(w))\n",
    "    print('\\ny : ',sess.run(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b :  [[-1.3222859  1.2233078]]\n",
      "w : \n",
      " [[ 3.0846481   1.2570065 ]\n",
      " [-0.27301225  0.8609854 ]\n",
      " [-0.29107988 -1.1276252 ]]\n",
      "\n",
      "y :  [[0.        1.4472575]]\n"
     ]
    }
   ],
   "source": [
    "# 這邊提供一個更簡便的寫法, 變數 run 一次 sess 就好\n",
    "\n",
    "x = tf.Variable([[0.4,0.2,0.4]])\n",
    "w = tf.Variable(tf.random_normal([3,2]))\n",
    "b = tf.Variable(tf.random_normal([1,2]))\n",
    "y = tf.nn.relu(tf.matmul(x,w)+b)\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    (b,w,y) = sess.run((b,w,y))\n",
    "    print('b : ',b)\n",
    "    print('w : \\n',w)\n",
    "    print('\\ny : ',y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x :  [[0.4 0.2 0.4]]\n",
      "b :  [[-0.8287806  1.9377056]]\n",
      "w : \n",
      " [[ 1.259302   -0.026501  ]\n",
      " [-1.1970146   0.82814115]\n",
      " [ 0.07466117  0.70939994]]\n",
      "\n",
      "y :  [[0.        2.3764935]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(\"float\",[None,3])\n",
    "w = tf.Variable(tf.random_normal([3,2]))\n",
    "b = tf.Variable(tf.random_normal([1,2]))\n",
    "y = tf.nn.relu(tf.matmul(x,w)+b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    x_array = np.array([[0.4,0.2,0.4]])\n",
    "    (x,w,b,y) = sess.run((x,w,b,y),feed_dict={x:x_array})\n",
    "    \n",
    "    print('x : ',x)\n",
    "    print('b : ',b)\n",
    "    print('w : \\n',w)\n",
    "    print('\\ny : ',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : \n",
      " [[0.4 0.2 0.4]\n",
      " [0.1 4.  1.2]\n",
      " [0.  1.  2. ]]\n",
      "b :  [[-0.55877167 -1.3260434 ]]\n",
      "w : \n",
      " [[-0.28018802 -0.075677  ]\n",
      " [ 1.7551091  -1.0545963 ]\n",
      " [-0.4596087  -0.88853693]]\n",
      "\n",
      "y :  [[0.        0.       ]\n",
      " [5.8821154 0.       ]\n",
      " [0.27712   0.       ]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(\"float\",[None,3])\n",
    "w = tf.Variable(tf.random_normal([3,2]))\n",
    "b = tf.Variable(tf.random_normal([1,2]))\n",
    "y = tf.nn.relu(tf.matmul(x,w)+b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    x_array = np.array([[0.4,0.2,0.4],[0.1,4,1.2],[0,1,2]])\n",
    "    (x,w,b,y) = sess.run((x,w,b,y),feed_dict={x:x_array})\n",
    "    \n",
    "    print('x : \\n',x)\n",
    "    print('b : ',b)\n",
    "    print('w : \\n',w)\n",
    "    print('\\ny : ',y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='dark'>Simple exercise : using layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之後我們要建立多層感知層，為方便做調用，可以建立 layer 這個 function 來做使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(output_dim, input_dim, inputs,activation=None):\n",
    "    w = tf.Variable(tf.random_normal([input_dim,output_dim]))\n",
    "    b = tf.Variable(tf.random_normal([1,output_dim]))\n",
    "    xwb = tf.matmul(inputs,w)+b\n",
    "    if activation is None:\n",
    "        output = xwb\n",
    "    else:\n",
    "        output = activation(xwb)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : \n",
      " [[0.4 0.2 0.4 0.5]] \n",
      "\n",
      "h : \n",
      " [[1.389194  0.8167518 0.       ]] \n",
      "\n",
      "y : \n",
      " [[0.8279882 2.4592144]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build the input layer \n",
    "x = tf.placeholder(\"float\",[None,4])\n",
    "\n",
    "# build the hidden layer\n",
    "h = layer(output_dim=3, input_dim=4, inputs=x,activation=tf.nn.relu)\n",
    "\n",
    "# build the output layer\n",
    "y = layer(output_dim=2,input_dim=3,inputs=h)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    x_array = np.array([[0.4, 0.2, 0.4, 0.5]])\n",
    "    \n",
    "    (x,h,y) = sess.run((x,h,y),feed_dict={x:x_array})\n",
    "    \n",
    "    print('x : \\n',x,'\\n')\n",
    "    print('h : \\n',h,'\\n')\n",
    "    print('y : \\n',y,'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
